# -*- coding: utf-8 -*-
"""crop_recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F-qUDRk2VVajQip0C0T8a4BEYSZmk38n

# Sistema de recomenda√ß√£o de cultivo

## üß†Business Understanding

### üíº Contexto

A empresa AgroIntelliTech (Fict√≠cia), especializada em solu√ß√µes de agricultura de precis√£o, est√° desenvolvendo um sistema inteligente para recomendar a cultura ideal para cada √°rea de cultivo. O objetivo √© ajudar agricultores a maximizar o rendimento agr√≠cola com base em vari√°veis ambientais e qu√≠micas do solo, reduzindo riscos e melhorando a efici√™ncia do plantio.

### üéØ Objetivo do Projeto

Construir um modelo de recomenda√ß√£o que, a partir de caracter√≠sticas do solo e clima (como N, P, K, pH, temperatura, umidade e precipita√ß√£o), indique a cultura agr√≠cola mais apropriada para determinada localidade.

## üìä Data Understanding

### üìÅ Descri√ß√£o do Conjunto de Dados

O dataset cont√©m 8 colunas com os seguintes atributos:

- N, P, K: N√≠veis de nitrog√™nio, f√≥sforo e pot√°ssio no solo (macronutrientes essenciais para o crescimento das plantas).

- temperature: Temperatura m√©dia (¬∞C).

- humidity: Umidade relativa do ar (%).

- ph: N√≠vel de acidez do solo.

- rainfall: Quantidade m√©dia de chuva (mm).

- label: Cultura agr√≠cola recomendada (alvo a ser previsto).

### EDA

#### Setup
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, scale, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.pipeline import Pipeline

import joblib

"""#### Carregando dados"""

df = pd.read_csv('Crop_recommendation.csv')
df.head()

"""#### An√°lise dos dados"""

df.info()

df.describe()

# Dados faltantes
df.isna().sum().sort_values(ascending=False)

# Dados duplicados
df.duplicated().sum().any()

# Distribui√ß√£o das classes (cultivos)
plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='label')
plt.xticks(rotation=90)
plt.title("Distribui√ß√£o dos Cultivos")
plt.show()

df.drop('label', axis = 1).apply(scale).plot.box(figsize=(12,8))

"""Insigths
- O dataset n√£o possui dados faltantes ou duplicados;
- Possui alguns outliers, por√©m nada ao extremo, vamos continuar com os dados pois deve-se considerar a variabilidade clim√°tica da regi√£o em estudo.
- Distribui√ß√£o das classes de forma totalmente balanceada.

#### Data Preparation
"""

X = df.drop('label', axis=1)
y = df['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Normaliza√ß√£o dos dados de treino
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# LabelEncoder apenas para y
le = LabelEncoder()
y_train_encoded = le.fit_transform(y_train)
y_test_encoded = le.transform(y_test)

# Contagem de classes
class_counts = pd.Series(y_train).value_counts()

# Porcentagens
class_percent = pd.Series(y_train).value_counts(normalize=True) * 100

pd.DataFrame({
    'Contagem': class_counts,
    'Porcentagem (%)': class_percent.round(2)  # 2 casas decimais
}).T

"""#### Modelagem dos dados"""

#Modelo: Random Forest
rf = RandomForestClassifier(random_state=42)
rf.fit(X_train_scaled, y_train)
y_pred_rf = rf.predict(X_test_scaled)

#modelo: SVM
svm = SVC(kernel='rbf', random_state=42)
svm.fit(X_train_scaled, y_train)
y_pred_svm = svm.predict(X_test_scaled)

#modelo: redes neurais mlp
mlp = MLPClassifier(hidden_layer_sizes=(64, 32),
                   activation='relu',
                   solver='adam',
                   max_iter=500,
                   random_state=42)

# Treinar
mlp.fit(X_train_scaled, y_train)

# Prever
y_pred_mlp = mlp.predict(X_test_scaled)

"""#### Avalia√ß√£o dos resultados"""

# Dicion√°rio para armazenar os resultados
results = {}

# Fun√ß√£o para extrair m√©tricas do classification report
def get_metrics_report(y_true, y_pred):
    report = classification_report(y_true, y_pred, output_dict=True)
    metrics = {
        'accuracy': report['accuracy'],
        'macro_avg_precision': report['macro avg']['precision'],
        'macro_avg_recall': report['macro avg']['recall'],
        'macro_avg_f1': report['macro avg']['f1-score']
    }
    return metrics

# Adicionando resultados de cada modelo ao dicion√°rio
results['Random Forest'] = get_metrics_report(y_test, y_pred_rf)
results['SVM'] = get_metrics_report(y_test, y_pred_svm)
results['MLP'] = get_metrics_report(y_test, y_pred_mlp)

# Criar DataFrame comparativo
df_comparativo = pd.DataFrame(results).T
df_comparativo = df_comparativo.sort_values('accuracy', ascending=False)

# Exibir o DataFrame
print("Comparativo de Desempenho dos Modelos:")
df_comparativo

"""#### Pipeline"""

pipeline = Pipeline([
    ('scaler', StandardScaler()),  # Normaliza√ß√£o
    ('classifier', RandomForestClassifier(random_state=42))  # Modelo
])

#Treino
pipeline.fit(X_train, y_train)

#Salvando a pipeline
joblib.dump(pipeline, 'crop_recommendation_pipeline.joblib')
joblib.dump(le, 'label_encoder.joblib')

import joblib

# Carregar pipeline e encoder
pipeline = joblib.load('crop_recommendation_pipeline.joblib')
le = joblib.load('label_encoder.joblib')

# Nova amostra (N, P, K, temperature, humidity, ph, rainfall)
new_sample = [[90, 42, 43, 20.8, 82, 6.5, 203]]  # Valores de exemplo

# Fazer predi√ß√£o
predicted_class = pipeline.predict(new_sample)
print(f"Recomenda√ß√£o: {predicted_class}")

